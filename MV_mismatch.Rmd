---
title: "Multivariate mismatched seedling traits vs. seed microbiome"
author: "Quentin D. Read"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
---

```{css, echo = FALSE}
.gt_table {
    margin-bottom: 20px;
    margin-top: 20px;
}
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Summary

In this document I extend the single-variable approach from the previous notebook to a multivariate approach. The initial model fitting to get trait BLUPs for each maternal plant is done with a multivariate linear regression. The predictions it produces are really no different than what you would get if you fit a lot of univariate models, just that it also outputs residual correlations between the traits (which we ignore moving forward anyway). Then, instead of a random forest model, a multiple-output neural network model is fit, again we do this repeatedly for every posterior sample. Leave-one-out cross-validation is used. 

The performance of the neural network is extremely bad in terms of predicting traits. In fact it is so bad that I am concerned I did something wrong. Being bad at machine learning things, I wanted to share this with the group to see if there is something that can be tweaked to improve the model. But even if things are tweaked, I think there really is not much signal in the data so this dataset will not give us much insight about relationship between seed microbiome and the traits of the resulting seedling. Not having microbiome and traits from the same seedlings, but only from siblings or half-siblings of the same mother plant, may be obscuring any relationship that does exist.

# Setup

```{r load packages}
library(data.table)
library(brms)
library(ggplot2)
library(purrr)
library(keras)

options(mc.cores = 4, brms.backend = 'cmdstanr', brms.file_refit = 'on_change')

# Import data. Corrected labels, data accessed from g drive 2023-06-06
abundance <- fread('project/data/16S_abundance.csv')
traits <- fread('project/data/seedling_data_updated.csv')
```


```{r ggplot theme, include = FALSE}
windowsFonts(`fgbook` = windowsFont('Franklin Gothic Book'))
theme_set(
  theme_bw(base_family = 'fgbook') + 
    theme(panel.grid = element_blank(),
          strip.background = element_blank())
)
```

# Multivariate trait model

We will use the following traits: days to germination, leaf height, rooting depth, root tip count, number of primary roots, and number of leaves. 

First, eliminate any individuals that have no traits recorded. Also, there are some individuals that only have one trait recorded: days to germination. These will not contribute very much to the information about the maternal plant either, so we will remove them too. 

```{r}
mv_traits <- c("days_to_germinate", "leaf_height_cm", "rooting_depth_cm", "root_tip_count", "no_primary_roots", "no_leaves")

traits_std <- traits[apply(traits[, lapply(.SD, \(x) !is.na(x)), .SDcols = mv_traits], 1, sum) > 1, 
                     mget(c('maternal_plant_code', 'country_origin', mv_traits))]
```

We are left with 50 seedlings. Here are the ones that have any missing values. There are only 3, which are missing days to germination. Because there are so few, we will simply impute those missing values using the median from their maternal plant. This is acceptable to do with such a small number of missing values.

```{r}
traits_std[!complete.cases(traits_std)]
```

```{r}
traits_std[, days_to_germinate := ifelse(is.na(days_to_germinate), median(days_to_germinate, na.rm = TRUE), days_to_germinate),
           by = .(maternal_plant_code)]
```

Transform all variables with a log transformation. Use log(x+1) for leaf height and number of leaves because there are a few zero values.

```{r}
traits_std[, leaf_height_cm := leaf_height_cm + 1]
traits_std[, no_leaves := no_leaves + 1]
traits_std[, (mv_traits) := lapply(.SD, log), .SDcols = mv_traits]
```

Standardize the traits (z-transformation) so that they are in common units.

```{r}
traits_std[, (mv_traits) := lapply(.SD, scale), .SDcols = mv_traits]
```

Fit the multivariate linear regression model with population as fixed effect and random intercept for maternal plant. There will be 4000 posterior samples. This model takes about 2 minutes to compile and run. It is basically six regressions put together except that residual correlations between each pair of traits are also estimated.

```{r}
mv_trait_fit <- brm(
  mvbind(days_to_germinate, leaf_height_cm, rooting_depth_cm, root_tip_count, no_primary_roots, no_leaves) ~ country_origin + (1 | maternal_plant_code),
  data = traits_std, 
  chains = 4, iter = 2000, warmup = 1000, seed = 825,
  file = 'project/fits/mv_trait_fit'
)
```

Extract the posterior distribution of the BLUPs for each of the 9 maternal plants (plant J had no offspring with traits). If you add the fixed and random effect together you get a predicted value for each of the 4000 posterior samples for each maternal plant for each of the 6 traits, so this is a 4000x9x6 array.

```{r}
pred_grid <- unique(traits_std[, .(maternal_plant_code, country_origin)])

trait_post_blups <- predict(mv_trait_fit, newdata = pred_grid, summary = FALSE)
```

Reduce the number of posterior samples to 100 for easier calculation. Later if it becomes important to do so we can remove this step and parallelize the computations. We are left with a 100x9x6 array.

```{r}
set.seed(1104)
n_samples <- 100
trait_post_blups_subsample <- trait_post_blups[sample(1:dim(trait_post_blups)[1], n_samples), , ]
```

# Use aggregated microbiome to predict traits

This uses the quick and dirty method of using the aggregated microbiome (sums of taxa counts) of all the offspring of each maternal plant to represent the maternal microbiome. This will be a reasonably good estimate of the "mean" microbiome from each maternal plant but will not account for the uncertainty resulting from us being only able to obliquely observe the maternal microbiome through sampling the microbiomes of its offspring. Later we may be able to come up with a method, using Aldex2 or some other means, to account for this uncertainty.

Convert abundance data to longform and then create identifier columns for sample ID and maternal plant code. Sum the counts and then convert to a wideform with taxa as columns.

```{r}
abundance_long <- melt(abundance, id.vars = 'V1') 
abundance_long[, maternal_plant_code := substr(variable, 3, 3)]
abundance_long[, sampleID := substr(variable, 1, 2)]

abundance_wide <- dcast(abundance_long,  maternal_plant_code + sampleID ~ V1)

abundance_agg <- abundance_long[, .(value = sum(value)), by = .(V1, maternal_plant_code)]
abundance_agg_wide <- dcast(abundance_agg,  maternal_plant_code ~ V1)
```

Subset the aggregated data to get rid of maternal plant J which does not have any offspring trait data. The result, after removing column 1 (maternal plant identifier) is a 9x1432 matrix.

```{r}
abundance_agg_forfitting <- abundance_agg_wide[maternal_plant_code %in% pred_grid$maternal_plant_code, -1] |> as.matrix()
```

## Multi-output neural network model

### Fit the model with LOO cross-validation

Some of the following code was adapted from [this post](https://www.datatechnotes.com/2020/01/multi-output-regression-example-with.html). First, we need to create a Keras model. Here it is a neural network with an input layer, an output layer, and one layer in between. The inputs are vectors of length 1432 (the microbiomes) and the outputs are vectors of length 6 (the traits). The model will be fit using the `keras` package which means that Python code is running behind the scenes, using the `reticulate` package to call Python from within R.

Every iteration through this code, we redefine and recompile the model and fit a multi-output neural network model for a single posterior sample (a slice from the three dimensional array, which is a 9x6 matrix). Due to the small sample size, we do leave-one-out cross-validation on the model (use 8 of 9 maternal microbiomes, or 8x1432 matrix, to fit the model and predict the 9th, repeat until all 9 are predicted). 

We have two nested loops, the outer loop for the number of trait MC samples we are repeating the model fit for (100), and the inner loop to loop through the rows of the MC sample to do leave-one-out cross-validation. We return the observed and predicted values in each case.

> NOTE: After much work I was able to configure my laptop (Windows 10) so that this code would run on it. However it takes a little while to run, so I ran it on the SciNet HPC anyway. For any case with a larger dataset, it will be better to run on the HPC.

```{r, eval = FALSE}
results <- list()
for (i in 1:n_samples) {
  for (j in 1:nrow(pred_grid)) {
    # Define and compile model.
    nnetmodel <- keras_model_sequential() |>
      layer_dense(units = 100, activation = 'relu', input_shape = dim(abundance_agg_forfitting)[2]) |>
      layer_dropout(rate = 0.3) |>
      layer_dense(units = 32, activation = 'relu') |>
      layer_dropout(rate = 0.3) |>
      layer_dense(units = dim(trait_post_blups)[3], activation = 'linear')
    
    nnetmodel |> compile(loss = 'mse', optimizer = 'adam')
    
    # Create train and test split with just a single holdout row and the rest used for fitting.
    ab_train <- abundance_agg_forfitting[-j, ]
    ab_test <- abundance_agg_forfitting[j, , drop = FALSE]
    trait_train <- trait_post_blups_subsample[i, -j, ]
    trait_test <- t(as.matrix(trait_post_blups_subsample[i, j, ]))
    
    # Fit model and get predictions for the holdout row.
    nnetmodel |> fit(
      x = ab_train, y = trait_train, epochs = 1000, verbose = 0
    )
    
    results[[length(results) + 1]] <- data.frame(sample = i, row = j, predict(nnetmodel, ab_test))
    
  }
  message('Sample ', i, ' of ', n_samples, ' complete.')
}

results_df <- do.call(rbind, results)
fwrite(results_df, 'project/fits/nnet_mv_trait_results.csv')
```

### Examine results

Visualize the distributions of predicted and observed results. Note that everything here has been log-transformed and then standardized.

Calculate the RMSE for each of the traits for each posterior sample. Because the traits have been standardized, all results will be in standard deviation units.

```{r}
results_df <- fread('project/fits/nnet_mv_trait_results.csv')

rmse <- list()

for (i in 1:n_samples) {
  trait_obs <- trait_post_blups_subsample[i,,]
  trait_pred <- results_df[sample == i, -(1:2)]
  
  # RMSE for each column.
  rmse[[length(rmse) + 1]] <- sqrt(apply((trait_obs - trait_pred)^2, 2, mean))
}

rmse_df <- do.call(rbind, rmse) |> as.data.table() |> setnames(names(traits_std)[-(1:2)])
```

Show the distributions of the RMSEs.

```{r}
melt(rmse_df, variable.name = 'trait', value.name = 'RMSE') |>
  ggplot(aes(x = trait, y = RMSE)) +
  geom_boxplot()
```

These are remarkably high RMSEs, seeing as they are in standard deviation units. It seems like microbiome does not predict traits. However the results are so poor that I am concerned there is an issue with how the model is being fit. 

> If someone can give any critique on the model fitting part of this that could potentially improve the model performance, I would be interested to hear it!

Ultimately, I think that regardless of what statistical method is used, it may be that the relationship between seed microbiome and traits of the resulting seedling is very dependent on the individual seed. Because we do not have any one-to-one correspondence between seed microbiome and seedling traits, we may not be able to say that much about this relationship. We just have a set of seeds with microbiome sampled, and a set of seeds with traits sampled. They do not come from the same individuals. Yes, some are siblings or at least half-siblings because they come from the same maternal plant. However if the relationship between microbiome and traits is dependent on what components of the maternal microbiome happened to make it into one particular seed, then our data cannot uncover that relationship no matter what we do.